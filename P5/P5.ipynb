{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Implement a function that returns the adjacency matrix of one\n",
    "realization of the ER graph with given values of N and p. Watch out\n",
    "for the trap!#%% md"
   ],
   "id": "f071df33c85fe271"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def er_graph_adj_matrix(N, p):\n",
    "    A = np.zeros((N, N), dtype=int)\n",
    "\n",
    "    # fill only the upper triangle\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            if np.random.rand() < p:\n",
    "                A[i, j] = 1\n",
    "                A[j, i] = 1\n",
    "\n",
    "    return A\n"
   ],
   "id": "8fd8a4abe35f8049"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "A = er_graph_adj_matrix(50, 0.2)\n",
    "print(A)"
   ],
   "id": "7eb302ba9e254610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excercise 3.\n",
    "Draw resulting graph\n"
   ],
   "id": "1a2c3ea19aeafcbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_er_graph(N, p):\n",
    "    A = er_graph_adj_matrix(N, p)\n",
    "    G = nx.from_numpy_array(A)\n",
    "    pos = nx.spring_layout(G)\n",
    "    plt.figure()\n",
    "    nx.draw(G, pos, with_labels=True)\n",
    "    plt.show()\n",
    "    return A, G\n",
    "\n",
    "A, G = draw_er_graph(50, 0.2)\n"
   ],
   "id": "47634cc76be8037c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excercise 4.\n",
    "Draw histogram of degree distribution."
   ],
   "id": "b7958d902498c4f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_degree_histogram(A):\n",
    "    G = nx.from_numpy_array(A)\n",
    "\n",
    "    degrees = [d for n, d in G.degree()]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(degrees, bins=range(0, max(degrees) + 2))\n",
    "    plt.xlabel(\"Vertex degree\")\n",
    "    plt.ylabel(\"Number of vertices\")\n",
    "    plt.title(\"Degree distribution histogram\")\n",
    "    plt.show()\n",
    "\n",
    "N = 50\n",
    "p = 0.2\n",
    "\n",
    "A = er_graph_adj_matrix(N, p)\n",
    "draw_degree_histogram(A)\n"
   ],
   "id": "94180b2dadfa7c4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excercise 5.\n",
    "What degree of vertex distribution do we expect?\n"
   ],
   "id": "c51eae6388f91df6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In an Erdős–Rényi graph **G(N, p)**, the degree of each vertex follows a **binomial distribution**:\n",
    "\n",
    "$$\n",
    "\\deg(v) \\sim \\text{Binomial}(N-1,\\, p)\n",
    "$$\n",
    "\n",
    "**Expected degree:**\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\deg(v)] = (N-1)p\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "44410d6ac75f2c70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excercise 6.\n",
    "Give the mathematical justification for the Poisson approximation\n",
    "used."
   ],
   "id": "379d2552f3aa99cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In an Erdős–Rényi graph \\(G(N,p)\\), the degree of a fixed vertex has a binomial distribution\n",
    "$$\n",
    "\\deg(v) \\sim \\text{Binomial}(N-1, p).\n",
    "$$\n",
    "\n",
    "Let\n",
    "$$\n",
    "n = N - 1, \\quad X \\sim \\text{Binomial}(n, p).\n",
    "$$\n",
    "We choose\n",
    "$$\n",
    "p = \\frac{\\lambda}{n},\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "\\mathbb{E}[X] = np = \\lambda\n",
    "$$\n",
    "stays fixed as \\(n \\to \\infty\\).\n",
    "\n",
    "The binomial pmf is\n",
    "$$\n",
    "\\mathbb{P}(X = k)\n",
    "= \\binom{n}{k} p^k (1-p)^{n-k}\n",
    "= \\binom{n}{k} \\left(\\frac{\\lambda}{n}\\right)^k\n",
    "\\left(1 - \\frac{\\lambda}{n}\\right)^{n-k}.\n",
    "$$\n",
    "\n",
    "We now take the limit as \\(n \\to \\infty\\) for fixed \\(k\\).\n",
    "\n",
    "First term:\n",
    "$$\n",
    "\\binom{n}{k} \\left(\\frac{\\lambda}{n}\\right)^k\n",
    "= \\frac{n(n-1)\\cdots(n-k+1)}{k!} \\cdot \\frac{\\lambda^k}{n^k}\n",
    "= \\frac{\\lambda^k}{k!} \\prod_{j=0}^{k-1} \\left(1 - \\frac{j}{n}\\right)\n",
    "\\longrightarrow \\frac{\\lambda^k}{k!}.\n",
    "$$\n",
    "\n",
    "Second term:\n",
    "$$\n",
    "\\left(1 - \\frac{\\lambda}{n}\\right)^{n-k}\n",
    "= \\left(1 - \\frac{\\lambda}{n}\\right)^n\n",
    "  \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\n",
    "\\longrightarrow e^{-\\lambda} \\cdot 1\n",
    "= e^{-\\lambda}.\n",
    "$$\n",
    "\n",
    "Combining these limits:\n",
    "$$\n",
    "\\mathbb{P}(X = k)\n",
    "\\longrightarrow e^{-\\lambda} \\frac{\\lambda^k}{k!},\n",
    "$$\n",
    "which is exactly the pmf of a Poisson\\((\\lambda)\\) distribution.\n",
    "\n",
    "Therefore, for large \\(N\\) and small \\(p\\) with \\((N-1)p = \\lambda\\) fixed, the degree of a vertex in \\(G(N,p)\\) is well approximated by a Poisson\\((\\lambda)\\) distribution.\n"
   ],
   "id": "516b9ac39a968041"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excercise 7.\n",
    "Plot both the simulation results and analytically obtained\n",
    "distributions on one graph. Test appropriate hypotheses."
   ],
   "id": "e801a26ed642e99a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom, poisson, chisquare\n",
    "\n",
    "def compare_empirical_and_analytical(N, p):\n",
    "    A = er_graph_adj_matrix(N, p)\n",
    "\n",
    "    degrees = np.array([sum(row) for row in A])\n",
    "\n",
    "    k = np.arange(0, N)\n",
    "\n",
    "    # Observed counts on full support\n",
    "    counts_full = np.zeros_like(k, dtype=int)\n",
    "    values, counts = np.unique(degrees, return_counts=True)\n",
    "    counts_full[values] = counts\n",
    "\n",
    "    # Empirical probabilities\n",
    "    prob_emp = counts_full / counts_full.sum()\n",
    "\n",
    "    # Analytical Binomial distribution\n",
    "    prob_binom = binom.pmf(k, N - 1, p)\n",
    "\n",
    "    # Analytical Poisson approximation\n",
    "    lam = (N - 1) * p\n",
    "    prob_poisson = poisson.pmf(k, lam)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(k, prob_emp, alpha=0.5, label=\"Empirical (simulation)\")\n",
    "    plt.plot(k, prob_binom, \"o-\", label=\"Binomial\")\n",
    "    plt.plot(k, prob_poisson, \"s--\", label=\"Poisson approximation\")\n",
    "\n",
    "    plt.xlabel(\"Degree k\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(\"Degree distribution: empirical vs analytical\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Chi-square tests\n",
    "    n_vertices = len(degrees)\n",
    "\n",
    "    # Expected counts for binomial (already sums  - n_vertices)\n",
    "    exp_binom = prob_binom * n_vertices\n",
    "\n",
    "    # For Poisson, renormalize because we truncate the tail at k = 0..N-1\n",
    "    prob_poisson_trunc = prob_poisson / prob_poisson.sum()\n",
    "    exp_poisson = prob_poisson_trunc * n_vertices\n",
    "\n",
    "    chi_binom = chisquare(counts_full, f_exp=exp_binom)\n",
    "    chi_poisson = chisquare(counts_full, f_exp=exp_poisson)\n",
    "\n",
    "    print(\"Chi-square test (Binomial fit):\", chi_binom)\n",
    "    print(\"Chi-square test (Poisson fit):\", chi_poisson)\n",
    "\n",
    "\n",
    "# Run it:\n",
    "compare_empirical_and_analytical(50, 0.2)\n"
   ],
   "id": "69913cdfc8a26e3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excercises 8.\n",
    "Check dependence of the results of the previous excercise for\n",
    "various values of p and N.\n"
   ],
   "id": "c3a107f9cf087fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom, poisson, chisquare\n",
    "\n",
    "def fit_degree_distribution_once(N, p):\n",
    "    A = er_graph_adj_matrix(N, p)\n",
    "\n",
    "    degrees = np.array([sum(row) for row in A])\n",
    "\n",
    "    k = np.arange(0, N)\n",
    "\n",
    "    counts_full = np.zeros_like(k, dtype=int)\n",
    "    values, counts = np.unique(degrees, return_counts=True)\n",
    "    counts_full[values] = counts\n",
    "\n",
    "    n_vertices = len(degrees)\n",
    "\n",
    "    # Binomial probabilities and expected counts\n",
    "    prob_binom = binom.pmf(k, N - 1, p)\n",
    "    exp_binom = prob_binom * n_vertices\n",
    "\n",
    "    # Poisson probabilities and expected counts (truncated, renormalized)\n",
    "    lam = (N - 1) * p\n",
    "    prob_poisson = poisson.pmf(k, lam)\n",
    "    prob_poisson_trunc = prob_poisson / prob_poisson.sum()\n",
    "    exp_poisson = prob_poisson_trunc * n_vertices\n",
    "\n",
    "    # Chi-square tests\n",
    "    chi_binom = chisquare(counts_full, f_exp=exp_binom)\n",
    "    chi_poisson = chisquare(counts_full, f_exp=exp_poisson)\n",
    "\n",
    "    return chi_binom.pvalue, chi_poisson.pvalue\n"
   ],
   "id": "fb67ae0285fe0478"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def explore_N_p_dependence():\n",
    "    N_list = [50, 100, 200, 500]\n",
    "    p_list = [0.01, 0.05, 0.1, 0.2]\n",
    "    n_trials = 20  # number of simulations per (N, p)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for N in N_list:\n",
    "        for p in p_list:\n",
    "            binom_pvals = []\n",
    "            pois_pvals = []\n",
    "            for _ in range(n_trials):\n",
    "                pb, pp = fit_degree_distribution_once(N, p)\n",
    "                binom_pvals.append(pb)\n",
    "                pois_pvals.append(pp)\n",
    "\n",
    "            mean_binom = np.mean(binom_pvals)\n",
    "            mean_pois = np.mean(pois_pvals)\n",
    "\n",
    "            results.append((N, p, mean_binom, mean_pois))\n",
    "            print(f\"N={N:4d}, p={p:5.3f} -> \"\n",
    "                  f\"Binom p≈{mean_binom:.3f}, Poisson p≈{mean_pois:.3f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "results = explore_N_p_dependence()\n"
   ],
   "id": "4f5ba43c5adeb54c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check the above analytical result by simulation.",
   "id": "65625275554b2d94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_clustering(N, p, n_runs=100):\n",
    "    Cs = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        A = er_graph_adj_matrix(N, p)\n",
    "        G = nx.from_numpy_array(A)\n",
    "\n",
    "        # clustering coefficient of the whole graph\n",
    "        C = nx.average_clustering(G)\n",
    "        Cs.append(C)\n",
    "\n",
    "    return np.array(Cs)\n",
    "\n",
    "N = 200\n",
    "p_values = [0.01, 0.05, 0.1, 0.2]\n",
    "n_runs = 50\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in p_values:\n",
    "    Cs = simulate_clustering(N, p, n_runs)\n",
    "    C_mean = Cs.mean()\n",
    "    results.append((p, C_mean))\n",
    "    print(f\"p = {p:.2f},  simulated <C> ≈ {C_mean:.4f},  analytical = {p:.2f}\")\n",
    "\n",
    "# Plot results\n",
    "ps = [r[0] for r in results]\n",
    "C_means = [r[1] for r in results]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(ps, C_means, \"o-\", label=\"Simulated ⟨C⟩\")\n",
    "plt.plot(ps, ps, \"r--\", label=\"Analytical ⟨C⟩ = p\")\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"Average clustering coefficient\")\n",
    "plt.title(\"Clustering coefficient in G(N,p): simulation vs theory\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "284cdfb3ab4abc41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "P5.3 Generate and draw a graph consisting of 4 community each with\n",
    "N = 20 nodes and the probability of connection within the\n",
    "community higher than between them. Draw the result. How it\n",
    "depends on the parameter values? [2P]"
   ],
   "id": "a23d096d9bb259be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def community_graph_adj_matrix(num_communities=4, nodes_per_community=20,\n",
    "                               p_in=0.4, p_out=0.02):\n",
    "    N = num_communities * nodes_per_community\n",
    "    A = np.zeros((N, N), dtype=int)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            comm_i = i // nodes_per_community\n",
    "            comm_j = j // nodes_per_community\n",
    "            # choose probability depending on whether same community\n",
    "            p = p_in if comm_i == comm_j else p_out\n",
    "            if np.random.rand() < p:\n",
    "                A[i, j] = 1\n",
    "                A[j, i] = 1\n",
    "    return A\n",
    "\n",
    "def draw_community_graph(num_communities=4, nodes_per_community=20,\n",
    "                         p_in=0.4, p_out=0.02):\n",
    "    A = community_graph_adj_matrix(num_communities, nodes_per_community,\n",
    "                                   p_in, p_out)\n",
    "    G = nx.from_numpy_array(A)\n",
    "\n",
    "    # community labels\n",
    "    N = num_communities * nodes_per_community\n",
    "    communities = [i // nodes_per_community for i in range(N)]\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        node_color=communities,\n",
    "        cmap=plt.cm.Set1,\n",
    "        with_labels=False,\n",
    "        node_size=80\n",
    "    )\n",
    "    plt.title(f\"4-community graph, N=20 per community\\np_in={p_in}, p_out={p_out}\")\n",
    "    plt.show()\n",
    "\n",
    "    return A, G\n",
    "\n",
    "# Example run for the assignment:\n",
    "A, G = draw_community_graph(\n",
    "    num_communities=4,\n",
    "    nodes_per_community=20,\n",
    "    p_in=0.4,\n",
    "    p_out=0.02\n",
    ")\n"
   ],
   "id": "72fcbd75a1b49741"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "P5.4 Draw a graph of the averaged coefficient of clustering of the WS\n",
    "network against its parameter p. [1.5P]\n"
   ],
   "id": "a1dafac5bee674e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_ws_clustering(N=200, k=6, p_values=None, runs=20):\n",
    "    if p_values is None:\n",
    "        p_values = np.linspace(0, 1, 20)\n",
    "\n",
    "    C_means = []\n",
    "\n",
    "    for p in p_values:\n",
    "        Cs = []\n",
    "        for _ in range(runs):\n",
    "            G = nx.watts_strogatz_graph(N, k, p)\n",
    "            C = nx.average_clustering(G)\n",
    "            Cs.append(C)\n",
    "        C_means.append(np.mean(Cs))\n",
    "\n",
    "    return p_values, np.array(C_means)\n",
    "\n",
    "N = 200\n",
    "k = 6\n",
    "runs = 20\n",
    "p_values = np.linspace(0, 1, 20)\n",
    "\n",
    "ps, Cs = compute_ws_clustering(N, k, p_values, runs)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ps, Cs, \"o-\", label=\"WS average clustering\")\n",
    "plt.xlabel(\"Rewiring probability p\")\n",
    "plt.ylabel(\"Average clustering coefficient\")\n",
    "plt.title(\"Clustering coefficient of Watts–Strogatz network vs p\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "ccaf861a16dee10b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Implement configuration model and test when the procedure\n",
    "converge."
   ],
   "id": "b4c511a6c70a511f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def random_edge_swap(G, num_swaps, max_tries_per_swap=10):\n",
    "    G = G.copy()\n",
    "    edges = list(G.edges())\n",
    "    m = len(edges)\n",
    "\n",
    "    successful_swaps = 0\n",
    "\n",
    "    while successful_swaps < num_swaps:\n",
    "        # Try a few times to find a valid swap\n",
    "        for _ in range(max_tries_per_swap):\n",
    "            # pick two different edges at random\n",
    "            (u, v) = edges[random.randrange(m)]\n",
    "            (x, y) = edges[random.randrange(m)]\n",
    "            if len({u, v, x, y}) < 4:\n",
    "                continue  # edges share a node, skip\n",
    "\n",
    "            # try both possible rewirings\n",
    "            if random.random() < 0.5:\n",
    "                a, b = u, x\n",
    "                c, d = v, y\n",
    "            else:\n",
    "                a, b = u, y\n",
    "                c, d = v, x\n",
    "\n",
    "            # avoid self-loops\n",
    "            if a == b or c == d:\n",
    "                continue\n",
    "\n",
    "            # avoid creating multi-edges\n",
    "            if G.has_edge(a, b) or G.has_edge(c, d):\n",
    "                continue\n",
    "\n",
    "            # perform the swap\n",
    "            G.remove_edge(u, v)\n",
    "            G.remove_edge(x, y)\n",
    "            G.add_edge(a, b)\n",
    "            G.add_edge(c, d)\n",
    "\n",
    "            # update edge list\n",
    "            edges = list(G.edges())\n",
    "            m = len(edges)\n",
    "\n",
    "            successful_swaps += 1\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return G\n"
   ],
   "id": "eeb7c1b1ca828509"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test_configuration_model_convergence():\n",
    "    N = 200\n",
    "    k = 6\n",
    "    p_ws = 0.1\n",
    "    G0 = nx.watts_strogatz_graph(N, k, p_ws)\n",
    "\n",
    "    m = G0.number_of_edges()\n",
    "\n",
    "    # different levels of randomization: swaps per edge\n",
    "    swaps_per_edge_list = [0, 0.5, 1, 2, 5, 10, 20]\n",
    "\n",
    "    clustering_values = []\n",
    "\n",
    "    for s in swaps_per_edge_list:\n",
    "        num_swaps = int(s * m)\n",
    "        G = random_edge_swap(G0, num_swaps)\n",
    "\n",
    "        C = nx.average_clustering(G)\n",
    "        clustering_values.append(C)\n",
    "\n",
    "        print(f\"swaps/edge = {s:4.1f}, swaps = {num_swaps:5d}, \"\n",
    "              f\"avg clustering = {C:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(swaps_per_edge_list, clustering_values, \"o-\")\n",
    "    plt.xlabel(\"Number of swaps per edge\")\n",
    "    plt.ylabel(\"Average clustering coefficient\")\n",
    "    plt.title(\"Configuration model convergence (degree-preserving rewiring)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "test_configuration_model_convergence()\n"
   ],
   "id": "7977c786c5529b16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Partition Function and Probability Distribution for Networks with a Fixed Number of Edges\n",
    "\n",
    "### Theory\n",
    "\n",
    "We consider an ensemble of all simple undirected graphs with:\n",
    "- a fixed number of nodes \\(N\\),\n",
    "- a fixed number of edges \\(M\\),\n",
    "- a Hamiltonian \\(H(G)\\) defined for each graph \\(G\\).\n",
    "\n",
    "The **partition function** of this ensemble is:\n",
    "\n",
    "$$\n",
    "Z(\\beta) = \\sum_{G} e^{-\\beta H(G)},\n",
    "$$\n",
    "\n",
    "where the sum runs over all graphs with exactly \\(M\\) edges.\n",
    "This defines the **Boltzmann probability distribution** over graphs:\n",
    "\n",
    "$$\n",
    "P(G) = \\frac{e^{-\\beta H(G)}}{Z(\\beta)}.\n",
    "$$\n",
    "\n",
    "For small \\(N\\), we can enumerate all such graphs exactly and compute \\(Z\\) without approximation.\n",
    "\n",
    "---\n",
    "\n",
    "### Code explanation\n",
    "\n",
    "1. `all_graphs_fixed_edges(N, M)`\n",
    "   Generates **all simple graphs** with \\(N\\) nodes and exactly \\(M\\) edges by taking all \\(M\\)-element subsets of possible edges.\n",
    "\n",
    "2. `example_hamiltonian(G)`\n",
    "   Defines a sample Hamiltonian\n",
    "   \\( H(G) = -J \\times (\\text{number of triangles}) \\).\n",
    "   You can replace this with any other energy function.\n",
    "\n",
    "3. `compute_partition_function_and_distribution(...)`\n",
    "   - enumerates all graphs,\n",
    "   - computes their energies,\n",
    "   - evaluates Boltzmann weights \\(e^{-\\beta H(G)}\\),\n",
    "   - calculates the partition function\n",
    "     \\( Z = \\sum_G e^{-\\beta H(G)} \\),\n",
    "   - computes the normalized probabilities\n",
    "     \\( P(G) = e^{-\\beta H(G)} / Z \\).\n",
    "\n",
    "4. The last cell prints the partition function and, for each graph, its:\n",
    "   - energy \\(H(G)\\),\n",
    "   - probability \\(P(G)\\).\n",
    "\n",
    "This provides an exact statistical-mechanical description of the graph ensemble for small \\(N\\).\n"
   ],
   "id": "8081a4ba2cb5bd45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def all_graphs_fixed_edges(N, M):\n",
    "    nodes = list(range(N))\n",
    "    possible_edges = list(itertools.combinations(nodes, 2))\n",
    "\n",
    "    if M > len(possible_edges):\n",
    "        raise ValueError(\"M is larger than the total possible edges\")\n",
    "\n",
    "    # all combinations of M edges\n",
    "    for edge_subset in itertools.combinations(possible_edges, M):\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(edge_subset)\n",
    "        return_graph = G\n",
    "        yield return_graph\n",
    "\n",
    "\n",
    "def example_hamiltonian(G, J=1.0):\n",
    "    triangles_per_node = nx.triangles(G)\n",
    "    num_triangles = sum(triangles_per_node.values()) / 3\n",
    "    return -J * num_triangles\n",
    "\n",
    "\n",
    "def compute_partition_function_and_distribution(N, M, beta, H_func):\n",
    "    energies = []\n",
    "    graphs = []\n",
    "\n",
    "    for G in all_graphs_fixed_edges(N, M):\n",
    "        E = H_func(G)\n",
    "        energies.append(E)\n",
    "        graphs.append(G)\n",
    "\n",
    "    energies = np.array(energies, dtype=float)\n",
    "    boltz_weights = np.exp(-beta * energies)\n",
    "\n",
    "    Z = boltz_weights.sum()\n",
    "    probs = boltz_weights / Z\n",
    "\n",
    "    return Z, energies, probs, graphs\n",
    "\n",
    "\n",
    "N = 5\n",
    "M = 4\n",
    "beta = 1.0\n",
    "\n",
    "Z, energies, probs, graphs = compute_partition_function_and_distribution(\n",
    "    N=N,\n",
    "    M=M,\n",
    "    beta=beta,\n",
    "    H_func=example_hamiltonian\n",
    ")\n",
    "\n",
    "print(f\"Partition function Z = {Z:.6f}\")\n",
    "print(\"\\nList of all graphs with energies and probabilities:\\n\")\n",
    "for i, (E, p) in enumerate(zip(energies, probs)):\n",
    "    print(f\"Graph {i:2d} | H = {E:6.3f} | P(G) = {p:.6f}\")\n"
   ],
   "id": "cf27e01fa46ac37e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
